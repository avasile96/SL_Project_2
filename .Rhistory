knn.fit <- knn.reg(eliminated, test = NULL, y, k = 3, algorithm=c("kd_tree", "cover_tree", "brute"))
eleminated$Y = eliminated_Y
eliminated$Y = eliminated_Y
### KNN ###
eliminated_KNN <- eliminated
eliminated_KNN$Y = eliminated_Y
knn.fit <- knn.reg(eliminated_KNN, test = NULL, y, k = 3, algorithm=c("kd_tree", "cover_tree", "brute"))
### KNN ###
# eliminated_KNN <- eliminated
# eliminated_KNN$Y = eliminated_Y
knn.fit <- knn.reg(eliminated_KNN, test = NULL, scaled.y_train, k = 3, algorithm=c("kd_tree", "cover_tree", "brute"))
plot(knn.fit)
### LOADING PACKAGES ###
library(tidyverse) # really dunno
library(eqs2lavaan) # for plotting covariance
library(GGally) # plotting correlation
library(FNN) # knn
library(readr) # string to number
### LOADING DATA ###
training_data <- as_tibble(read.csv("D:\\Uni\\SL\\SL_Project\\train_ch.csv"))
test_data <- as_tibble(read.csv("D:\\Uni\\SL\\SL_Project\\train_ch.csv"))
x_train <- training_data %>% select(2:10)
y_train <- training_data %>% select(11)
x_test <- test_data %>% select(2:10)
y_test <- test_data %>% select(11)
# Eliminating outliers
eliminated <- x_train
eliminated_Y <- y_train
for (v in names(x_train)){
# print(v)
Q <- quantile(x_train[[v]], probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(x_train[[v]])
up <-  Q[2]+1.5*iqr # Upper Range
low<- Q[1]-1.5*iqr # Lower Range
eliminated_Y <- subset(eliminated_Y, eliminated[[v]] > (Q[1] - 1.5*iqr) & eliminated[[v]] < (Q[2]+1.5*iqr))
eliminated <- subset(eliminated, eliminated[[v]] > (Q[1] - 1.5*iqr) & eliminated[[v]] < (Q[2]+1.5*iqr))
}
# Standardization
scaled.x_train <- scale(eliminated)
scaled.y_train <- scale(eliminated_Y)
for (v in names(x_train)){
eliminated[[v]] = scaled.x_train[,parse_number(v)]
}
### REGRESSION ###
# Start with a basic regression using the **lm(y ~ x, data)** function
lm.fit <- lm(scaled.y_train ~ .-v5-v7, data = eliminated)
### KNN ###
# eliminated_KNN <- eliminated
# eliminated_KNN$Y = eliminated_Y
knn.fit <- knn.reg(eliminated_KNN, test = NULL, scaled.y_train, k = 3, algorithm=c("kd_tree", "cover_tree", "brute"))
### KNN ###
# eliminated_KNN <- eliminated
# eliminated_KNN$Y = eliminated_Y
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 3, algorithm=c("kd_tree", "cover_tree", "brute"))
View(knn.fit)
plot(knn.fit)
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 3, algorithm=c("kd_tree", "cover_tree", "brute"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
plot(scaled.y_train)
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 10, algorithm=c("kd_tree", "cover_tree", "brute"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 2, algorithm=c("kd_tree", "cover_tree", "brute"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 2, algorithm=c("kd_tree", "cover_tree", "brute"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 2, algorithm=c("kd_tree", "cover_tree", "brute"))
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 4, algorithm=c("kd_tree", "cover_tree", "brute"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
# eliminated_KNN <- eliminated
# eliminated_KNN$Y = eliminated_Y
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 4, algorithm=c("kd_tree", "cover_tree", "brute"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 100, algorithm=c("kd_tree", "cover_tree", "brute"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
### KNN ###
# eliminated_KNN <- eliminated
# eliminated_KNN$Y = eliminated_Y
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 3, algorithm=c("kd_tree", "cover_tree", "brute"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 3, algorithm=c("kd_tree"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 3, algorithm=c( "cover_tree"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 3, algorithm=c("brute"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 300, algorithm=c("kd_tree", "cover_tree", "brute"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 900, algorithm=c("kd_tree", "cover_tree", "brute"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 800, algorithm=c("kd_tree", "cover_tree", "brute"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
View(scaled.y_train)
pred_bread = knn.fit$pred
pred_bread
plot(pred_bread)
plot(scaled.y_train)
plot(pred_bread)
plot(scaled.y_train)
mean(scaled.y_train)
mean(pred_bread)
# eliminated_KNN$Y = eliminated_Y
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 10, algorithm=c("kd_tree", "cover_tree", "brute"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
### LOADING PACKAGES ###
library(tidyverse) # really dunno
library(eqs2lavaan) # for plotting covariance
library(GGally) # plotting correlation
library(FNN) # knn
library(readr) # string to number
### LOADING DATA ###
training_data <- as_tibble(read.csv("D:\\Uni\\SL\\SL_Project\\train_ch.csv"))
test_data <- as_tibble(read.csv("D:\\Uni\\SL\\SL_Project\\train_ch.csv"))
x_train <- training_data %>% select(2:10)
y_train <- training_data %>% select(11)
x_test <- test_data %>% select(2:10)
y_test <- test_data %>% select(11)
# Eliminating outliers
eliminated <- x_train
eliminated_Y <- y_train
eliminated <- x_train
eliminated_Y <- y_train
for (v in names(x_train)){
# print(v)
Q <- quantile(x_train[[v]], probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(x_train[[v]])
up <-  Q[2]+1.5*iqr # Upper Range
low<- Q[1]-1.5*iqr # Lower Range
eliminated_Y <- subset(eliminated_Y, eliminated[[v]] > (Q[1] - 1.5*iqr) & eliminated[[v]] < (Q[2]+1.5*iqr))
eliminated <- subset(eliminated, eliminated[[v]] > (Q[1] - 1.5*iqr) & eliminated[[v]] < (Q[2]+1.5*iqr))
}
# Standardization
scaled.x_train <- scale(eliminated)
scaled.y_train <- scale(eliminated_Y)
for (v in names(x_train)){
eliminated[[v]] = scaled.x_train[,parse_number(v)]
}
### REGRESSION ###
# Start with a basic regression using the **lm(y ~ x, data)** function
lm.fit <- lm(scaled.y_train ~ .-v5-v7, data = eliminated)
plot(lm.fit)
# eliminated_KNN$Y = eliminated_Y
knn.fit <- knn.reg(eliminated, test = NULL, scaled.y_train, k = 10, algorithm=c("kd_tree", "cover_tree", "brute"))
plot(scaled.y_train, knn.fit$pred, xlab="y", ylab=expression(hat(scaled.y_train)))
library(tensorflow)
install_tensorflow(version = 'gpu')
install.packages("tensorflow")
install_tensorflow(version = 'gpu')
library(tensorflow)
install_tensorflow(version = 'gpu')
y
library(tensorflow)
hello <- tf$constant("Hello")
print(hello)
library(purrr)
library(keras)
library(tfdatasets)
library(tfautograph)
library(reticulate)
library(purrr)
install.packages("keras")
library(keras)
library(tfdatasets)
library(tfautograph)
library(reticulate)
library(purrr)
mnist <- dataset_mnist()
mnist$train$x <- mnist$train$x/255
mnist$test$x <- mnist$test$x/255
dim(mnist$train$x) <- c(dim(mnist$train$x), 1)
dim(mnist$test$x) <- c(dim(mnist$test$x), 1)
train_ds <- mnist$train %>%
tensor_slices_dataset() %>%
dataset_take(20000) %>%
dataset_map(~modify_at(.x, "x", tf$cast, dtype = tf$float32)) %>%
dataset_map(~modify_at(.x, "y", tf$cast, dtype = tf$int64)) %>%
dataset_shuffle(10000) %>%
dataset_batch(32)
test_ds <- mnist$test %>%
tensor_slices_dataset() %>%
dataset_take(2000) %>%
dataset_map(~modify_at(.x, "x", tf$cast, dtype = tf$float32)) %>%
dataset_map(~modify_at(.x, "y", tf$cast, dtype = tf$int64)) %>%
dataset_batch(32)
train_ds <- mnist$train %>%
tensor_slices_dataset() %>%
dataset_take(20000) %>%
dataset_map(~modify_at(.x, "x", tf$cast, dtype = tf$float32)) %>%
dataset_map(~modify_at(.x, "y", tf$cast, dtype = tf$int64)) %>%
dataset_shuffle(10000) %>%
dataset_batch(32)
library(keras)
library(tfdatasets)
library(tfautograph)
library(reticulate)
library(purrr)
mnist <- dataset_mnist()
mnist$train$x <- mnist$train$x/255
mnist$test$x <- mnist$test$x/255
dim(mnist$train$x) <- c(dim(mnist$train$x), 1)
dim(mnist$test$x) <- c(dim(mnist$test$x), 1)
train_ds <- mnist$train %>%
tensor_slices_dataset() %>%
dataset_take(20000) %>%
dataset_map(~modify_at(.x, "x", tf$cast, dtype = tf$float32)) %>%
dataset_map(~modify_at(.x, "y", tf$cast, dtype = tf$int64)) %>%
dataset_shuffle(10000) %>%
dataset_batch(32)
test_ds <- mnist$test %>%
tensor_slices_dataset() %>%
dataset_take(2000) %>%
dataset_map(~modify_at(.x, "x", tf$cast, dtype = tf$float32)) %>%
dataset_map(~modify_at(.x, "y", tf$cast, dtype = tf$int64)) %>%
dataset_batch(32)
simple_conv_nn <- function(filters, kernel_size) {
keras_model_custom(name = "MyModel", function(self) {
self$conv1 <- layer_conv_2d(
filters = filters,
kernel_size = rep(kernel_size, 2),
activation = "relu"
)
self$flatten <- layer_flatten()
self$d1 <- layer_dense(units = 128, activation = "relu")
self$d2 <- layer_dense(units = 10, activation = "softmax")
function(inputs, mask = NULL) {
inputs %>%
self$conv1() %>%
self$flatten() %>%
self$d1() %>%
self$d2()
}
})
}
model <- simple_conv_nn(filters = 32, kernel_size = 3)
train_ds <- mnist$train %>%
tensor_slices_dataset() %>%
dataset_take(20000) %>%
dataset_map(~modify_at(.x, "x", tf$cast, dtype = tf$float32)) %>%
dataset_map(~modify_at(.x, "y", tf$cast, dtype = tf$int64)) %>%
dataset_shuffle(10000) %>%
dataset_batch(32)
loss <- loss_sparse_categorical_crossentropy
optimizer <- optimizer_adam()
train_loss <- tf$keras$metrics$Mean(name='train_loss')
train_accuracy <-  tf$keras$metrics$SparseCategoricalAccuracy(name='train_accuracy')
test_loss <- tf$keras$metrics$Mean(name='test_loss')
test_accuracy <- tf$keras$metrics$SparseCategoricalAccuracy(name='test_accuracy')
train_step <- function(images, labels) {
with (tf$GradientTape() %as% tape, {
predictions <- model(images)
l <- loss(labels, predictions)
})
gradients <- tape$gradient(l, model$trainable_variables)
optimizer$apply_gradients(purrr::transpose(list(
gradients, model$trainable_variables
)))
train_loss(l)
train_accuracy(labels, predictions)
}
test_step <- function(images, labels) {
predictions <- model(images)
l <- loss(labels, predictions)
test_loss(l)
test_accuracy(labels, predictions)
}
training_loop <- tf_function(autograph(function(train_ds, test_ds) {
for (b1 in train_ds) {
train_step(b1$x, b1$y)
}
for (b2 in test_ds) {
test_step(b2$x, b2$y)
}
tf$print("Acc", train_accuracy$result(), "Test Acc", test_accuracy$result())
train_loss$reset_states()
train_accuracy$reset_states()
test_loss$reset_states()
test_accuracy$reset_states()
}))
for (epoch in 1:5) {
cat("Epoch: ", epoch, " -----------\n")
training_loop(train_ds, test_ds)
}
### LOADING PACKAGES ###
library(tidyverse) # really dunno
library(eqs2lavaan) # for plotting covariance
library(GGally) # plotting correlation
library(FNN) # knn
library(readr) # string to number
library(Metrics)
library(caret) # normalization
library(Directional) # another knn (regression tuning)
library(dplyr) # for finding strings in column names
### LOADING DATA ###
setwd("D:\\Uni\\SL\\SL_Project_2\\")
ADCN_train <- as_tibble(read.csv(".\\dataset\\ADCNtrain.csv"))
ADCN_test <- as_tibble(read.csv(".\\dataset\\ADCNtest.csv"))
x_ADCN_train <- ADCN_train %>% select(2:567)
y_ADCN_train <- as.integer(ADCN_train$Labels == 'CN')
select(x_ADCN_train,matches("ippo"))
select(x_ADCN_train,matches("APOE"))
select(x_ADCN_train,matches("APO"))
select(x_ADCN_train,matches("APP"))
select(x_ADCN_train,matches("AP"))
select(x_ADCN_train,matches("APE"))
select(x_ADCN_train,matches("APOE"))
select(x_ADCN_train,matches("e2"))
select(x_ADCN_train,matches("APP"))
select(x_ADCN_train,matches("PSEN1"))
select(x_ADCN_train,matches("PSEN"))
select(x_ADCN_train,matches("PSE"))
select(x_ADCN_train,matches("PS"))
select(x_ADCN_train,matches("APP"))
select(x_ADCN_train,matches("PSEN1"))
select(x_ADCN_train,matches("PSEN2"))
select(x_ADCN_train,matches("APO"))
View(x_ADCN_train)
select(x_ADCN_train,matches("AM2"))
select(x_ADCN_train,matches("A2M"))
select(x_ADCN_train,matches("ABCA5"))
select(x_ADCN_train,matches("ABCA7"))
select(x_ADCN_train,matches("ABCA"))
select(x_ADCN_train,matches("ACOD"))
select(x_ADCN_train,matches("AD"))
select(x_ADCN_train,matches("AXANA"))
select(x_ADCN_train,matches("ANXA7"))
select(x_ADCN_train,matches("APBA2"))
select(x_ADCN_train,matches("APBB2"))
select(x_ADCN_train,matches("APH1A"))
select(x_ADCN_train,matches("APH1B"))
select(x_ADCN_train,matches("APOC1"))
select(x_ADCN_train,matches("APOC"))
select(x_ADCN_train,matches("APP"))
select(x_ADCN_train,matches("ATG13"))
select(x_ADCN_train,matches("ATP5F1C"))
select(x_ADCN_train,matches("BACE"))
select(x_ADCN_train,matches("BCL"))
select(x_ADCN_train,matches("BHL"))
select(x_ADCN_train,matches("C10"))
select(x_ADCN_train,matches("CALHM"))
select(x_ADCN_train,matches("CD"))
select(x_ADCN_train,matches("CDK5R1"))
select(x_ADCN_train,matches("CD"))
select(x_ADCN_train,matches("CHR"))
select(x_ADCN_train,matches("CLSTN"))
select(x_ADCN_train,matches("CLS"))
select(x_ADCN_train,matches("CL"))
select(x_ADCN_train,matches("CSN"))
select(x_ADCN_train,matches("CYP"))
select(x_ADCN_train,matches("DBN"))
select(x_ADCN_train,matches("DCT"))
select(x_ADCN_train,matches("DHC"))
select(x_ADCN_train,matches("DHR"))
select(x_ADCN_train,matches("DKK"))
select(x_ADCN_train,matches("DPY"))
select(x_ADCN_train,matches("ECE"))
select(x_ADCN_train,matches("ECE2"))
select(x_ADCN_train,matches("ECE"))
select(x_ADCN_train,matches("EXO"))
select(x_ADCN_train,matches("FAM"))
select(x_ADCN_train,matches("FCH"))
select(x_ADCN_train,matches("FLOT"))
select(x_ADCN_train,matches("FPR"))
select(x_ADCN_train,matches("FRA"))
select(x_ADCN_train,matches("GAB"))
select(x_ADCN_train,matches("GAL"))
select(x_ADCN_train,matches("GALR"))
select(x_ADCN_train,matches("GAPDH"))
select(x_ADCN_train,matches("GOL"))
select(x_ADCN_train,matches("GPR"))
select(x_ADCN_train,matches("GRI"))
select(x_ADCN_train,matches("GSA"))
select(x_ADCN_train,matches("GSK"))
select(x_ADCN_train,matches("GST"))
select(x_ADCN_train,matches("HAR"))
select(x_ADCN_train,matches("HDA"))
select(x_ADCN_train,matches("HELT"))
select(x_ADCN_train,matches("HNR"))
select(x_ADCN_train,matches("HPC"))
select(x_ADCN_train,matches("HSD"))
select(x_ADCN_train,matches("HVC"))
select(x_ADCN_train,matches("IDE"))
select(x_ADCN_train,matches("INA"))
select(x_ADCN_train,matches("INAF"))
select(x_ADCN_train,matches("INSRR"))
select(x_ADCN_train,matches("INSR"))
select(x_ADCN_train,matches("INS"))
select(x_ADCN_train,matches("JCA"))
select(x_ADCN_train,matches("KCN"))
select(x_ADCN_train,matches("KLR"))
select(x_ADCN_train,matches("LIL"))
select(x_ADCN_train,matches("LIN"))
select(x_ADCN_train,matches("LINC"))
select(x_ADCN_train,matches("LRP"))
select(x_ADCN_train,matches("LRR"))
select(x_ADCN_train,matches("MAP"))
select(x_ADCN_train,matches("MARK"))
select(x_ADCN_train,matches("MINK"))
select(x_ADCN_train,matches("MIR"))
select(x_ADCN_train,matches("MPO"))
select(x_ADCN_train,matches("MS4"))
select(x_ADCN_train,matches("MSRB"))
select(x_ADCN_train,matches("MT1"))
select(x_ADCN_train,matches("MT3"))
select(x_ADCN_train,matches("MTH"))
select(x_ADCN_train,matches("MYO"))
select(x_ADCN_train,matches("NAE"))
select(x_ADCN_train,matches("NOS"))
select(x_ADCN_train,matches("NPE"))
select(x_ADCN_train,matches("NRB"))
select(x_ADCN_train,matches("NRG"))
select(x_ADCN_train,matches("OLF"))
select(x_ADCN_train,matches("PALD"))
select(x_ADCN_train,matches("PAWR"))
select(x_ADCN_train,matches("PCD"))
select(x_ADCN_train,matches("PEB"))
select(x_ADCN_train,matches("PIK"))
select(x_ADCN_train,matches("PIN"))
select(x_ADCN_train,matches("PITRM"))
select(x_ADCN_train,matches("PLA"))
select(x_ADCN_train,matches("PLD"))
select(x_ADCN_train,matches("PP"))
select(x_ADCN_train,matches("PPT"))
select(x_ADCN_train,matches("PSE"))
select(x_ADCN_train,matches("PSM"))
select(x_ADCN_train,matches("PTP"))
select(x_ADCN_train,matches("RALG"))
select(x_ADCN_train,matches("RMDN"))
select(x_ADCN_train,matches("RM"))
select(x_ADCN_train,matches("RTN"))
select(x_ADCN_train,matches("SEM"))
select(x_ADCN_train,matches("SNH"))
select(x_ADCN_train,matches("SOR"))
select(x_ADCN_train,matches("SPP"))
select(x_ADCN_train,matches("TFC"))
select(x_ADCN_train,matches("THO"))
select(x_ADCN_train,matches("THR"))
select(x_ADCN_train,matches("TIP"))
select(x_ADCN_train,matches("TM"))
select(x_ADCN_train,matches("TNF"))
select(x_ADCN_train,matches("TOM"))
select(x_ADCN_train,matches("TRP"))
select(x_ADCN_train,matches("TUB"))
select(x_ADCN_train,matches("UBQ"))
select(x_ADCN_train,matches("UNC"))
select(x_ADCN_train,matches("UQ"))
select(x_ADCN_train,matches("VDA"))
select(x_ADCN_train,matches("VPS"))
select(x_ADCN_train,matches("VSN"))
select(x_ADCN_train,matches("WN"))
select(x_ADCN_train,matches("YW"))
select(x_ADCN_train,matches("..."))
select(x_ADCN_train,matches(".."))
select(x_ADCN_train,matches("alzhe"))
select(x_ADCN_train,matches("cy"))
select(x_ADCN_train,matches("cyp"))
select(x_ADCN_train,matches("en5g"))
select(x_ADCN_train,matches("EN"))
select(x_ADCN_train,matches("EN5"))
select(x_ADCN_train,matches("HLA"))
select(x_ADCN_train,matches("SLC6"))
select(x_ADCN_train,matches("SRP"))
select(x_ADCN_train,matches("hippo"))
select(x_ADCN_train,matches("hippoca"))
select(x_ADCN_train,matches("enth"))
select(x_ADCN_train,matches("ent"))
select(x_ADCN_train,matches("ento"))
select(x_ADCN_train,matches("frontal"))
select(x_ADCN_train,matches("tempo"))
select(x_ADCN_train,matches("parie"))
select(x_ADCN_train,matches("parietal"))
select(x_ADCN_train,matches("parie"))
select(x_ADCN_train,matches("hipoth"))
select(x_ADCN_train,matches("hipota"))
select(x_ADCN_train,matches("talamus"))
select(x_ADCN_train,matches("tala"))
select(x_ADCN_train,matches("tal"))
select(x_ADCN_train,matches("amyg"))
select(x_ADCN_train,matches("cere"))
select(x_ADCN_train,matches("call"))
select(x_ADCN_train,matches("cal"))
select(x_ADCN_train,matches("call"))
# correlation
train_cor = cor(x_ADCN_train)
dim(train_cor)
View(train_cor)
# correlation
train_cor = cor(ADCN_train)
View(ADCN_train)
x_ADCN_train$Labels <- as.integer(ADCN_train$Labels == 'CN')
y_ADCN_train <- as.integer(ADCN_train$Labels == 'CN')
# correlation
train_cor = cor(ADCN_train)
# correlation
train_cor = cor(x_ADCN_train)
View(ADCN_train)
save(train_cor, file = "train_corr.tiff")
save(train_cor, file = "train_corr.tiff")
save(train_cor, file = "train_corr.png")
save(train_cor, file = "train_corr")
save.image(train_cor, file = "train_corr.tiff")
save.image(train_cor, file = "train_corr")
save.image(train_cor, file = "train_corr.png")
library(imager)
install.packages("imager")
library(imager) # dealing with images
plot(train_corr)
plot(train_cor)
grayscale(train_cor)
heatmap(train_cor)
heatmap(train_cor(vec,33,28),Rowv=NA,Colv=NA,col=paste("gray",1:99,sep=""))
heatmap(train_cor,Rowv=NA,Colv=NA,col=paste("gray",1:99,sep=""))
heatmap(train_cor)

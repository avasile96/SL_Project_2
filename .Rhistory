function(inputs, mask = NULL) {
inputs %>%
self$conv1() %>%
self$flatten() %>%
self$d1() %>%
self$d2()
}
})
}
model <- simple_conv_nn(filters = 32, kernel_size = 3)
train_ds <- mnist$train %>%
tensor_slices_dataset() %>%
dataset_take(20000) %>%
dataset_map(~modify_at(.x, "x", tf$cast, dtype = tf$float32)) %>%
dataset_map(~modify_at(.x, "y", tf$cast, dtype = tf$int64)) %>%
dataset_shuffle(10000) %>%
dataset_batch(32)
loss <- loss_sparse_categorical_crossentropy
optimizer <- optimizer_adam()
train_loss <- tf$keras$metrics$Mean(name='train_loss')
train_accuracy <-  tf$keras$metrics$SparseCategoricalAccuracy(name='train_accuracy')
test_loss <- tf$keras$metrics$Mean(name='test_loss')
test_accuracy <- tf$keras$metrics$SparseCategoricalAccuracy(name='test_accuracy')
train_step <- function(images, labels) {
with (tf$GradientTape() %as% tape, {
predictions <- model(images)
l <- loss(labels, predictions)
})
gradients <- tape$gradient(l, model$trainable_variables)
optimizer$apply_gradients(purrr::transpose(list(
gradients, model$trainable_variables
)))
train_loss(l)
train_accuracy(labels, predictions)
}
test_step <- function(images, labels) {
predictions <- model(images)
l <- loss(labels, predictions)
test_loss(l)
test_accuracy(labels, predictions)
}
training_loop <- tf_function(autograph(function(train_ds, test_ds) {
for (b1 in train_ds) {
train_step(b1$x, b1$y)
}
for (b2 in test_ds) {
test_step(b2$x, b2$y)
}
tf$print("Acc", train_accuracy$result(), "Test Acc", test_accuracy$result())
train_loss$reset_states()
train_accuracy$reset_states()
test_loss$reset_states()
test_accuracy$reset_states()
}))
for (epoch in 1:5) {
cat("Epoch: ", epoch, " -----------\n")
training_loop(train_ds, test_ds)
}
### LOADING PACKAGES ###
library(tidyverse) # really dunno
library(eqs2lavaan) # for plotting covariance
library(GGally) # plotting correlation
library(FNN) # knn
library(readr) # string to number
library(Metrics)
library(caret) # normalization
library(Directional) # another knn (regression tuning)
library(dplyr) # for finding strings in column names
library(imager) # dealing with images
library(ggplot2) # plotting
library(cowplot) # for nicer ggplots
library(e1071) # SVM
library (ROCR)
library(MLmetrics)
library(AUC)
library(mltools)
library(rpart)
library(pROC)
library(imbalance)
library(performanceEstimation)
library(DMwR)
### LOADING DATA / DATABASE SELECTION ###
setwd("D:\\Uni\\SL\\SL_Project_2\\")
db_train <- as.data.frame(read.csv(".\\dataset\\MCICNtrain.csv"))
db_test <- as.data.frame(read.csv(".\\dataset\\MCICNtest.csv"))
db_train$Labels <- as.factor(db_train$Labels)
# correlation
train_cor = cor(db_train[-c(1,ncol(db_train))])
remove(train_cor) # decluttering
# data imbalance exploration
numPositive <-length(which(db_train$Labels==levels(db_train$Labels)[1])) # ex: levels(db_train$Labels)[1] = "AD" for ADCN
numNegative <-length(which(db_train$Labels==levels(db_train$Labels)[2])) # coded for dynamic interchange of datasets
imb_idx <- imbalanceRatio(db_train, classAttr = "Labels")
# solving data imbalance
# balanced.train.data <- SMOTE(Labels ~., smote_data, perc.over = 100, perc.under = 200)
# “RACOG”, “RWO”, “ADASYN”, “ANSMOTE”, “SMOTE”, “MWMOTE”, “BLSMOTE”, “DBSMOTE”, “SLMOTE”, “RSLSMOTE”
# newSamples <- oversample(db_train[2:ncol(db_train)] ,method = "SMOTE",classAttr = 'Labels', ratio = imb_idx*2.5) # ADCN
# newSamples <- oversample(db_train[2:ncol(db_train)] ,method = "SMOTE",classAttr = 'Labels', ratio = imb_idx*4) # ADMCI
newSamples <- db_train[2:ncol(db_train)] # MCICN, with an imbalance index of ~0.58 is better left like this (rename just for semi-automation purpouses)
# new imbalance ratio
newSamples_imb_dx <- imbalanceRatio(newSamples, classAttr = "Labels") # check
# Normalization
norm_params <- preProcess(newSamples[-c(1,ncol(db_train))]) # getting normalization parameters
newSamples[-c(1,ncol(db_train))] <- predict(norm_params, newSamples[-c(1,ncol(db_train))]) # applying them
db_test <- predict(norm_params, db_test) # applying them to test data
# Renaming
x_train <- newSamples
y_train <- as.factor(x_train$Labels)
# Feature Selection based on medical insight
a <- c(names(select(x_train,matches("HLA"))),
names(select(x_train,matches("SLC6"))),
names(select(x_train,matches("SRP"))),
names(select(x_train,matches("hippoca"))),
names(select(x_train,matches("frontal"))),
names(select(x_train,matches("tempo"))),
names(select(x_train,matches("parie"))),
names(select(x_train,matches("amyg"))),
names(select(x_train,matches("call"))))
x_train <- select(x_train, a)
set.seed(42) # because 42 it's the answer to everything
train.control <- trainControl(method = "cv", number = 5)
knn.fit <- train(x_train[1:ncol(x_train)-1], y_train, method = "knn",
trControl = train.control,
tuneGrid = expand.grid(k = seq(from = 1, to = 20, by = 2)),
metric = "Accuracy")
print(knn.fit)
y_pred_knn <- predict(knn.fit, x_train) # predicting on training data
roc_knn <- roc(as.numeric(y_train), as.numeric(y_pred_knn)) # builds a ROC curve and returns a “roc” object
plot(roc_knn, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(roc_knn$auc[[1]],2))) # plot AUC
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
mcc_knn <- mcc(y_pred_knn, y_train)
best_features <- db_train[, !names(x_train) %in% "Labels"]
best_features <- names(best_features)
a <- c(names(select(x_train,matches("HLA"))),
names(select(x_train,matches("SLC6"))),
names(select(x_train,matches("SRP"))),
names(select(x_train,matches("hippoca"))),
names(select(x_train,matches("frontal"))),
names(select(x_train,matches("tempo"))),
names(select(x_train,matches("parie"))),
names(select(x_train,matches("amyg"))),
names(select(x_train,matches("call"))))
a
which(colnames(x_train) == "SLC6A8")
best_features = list()
i = 1
for (var in a){
best_features[i] <- which(colnames(x_train) == var)
i = i+1
}
View(best_features)
best_features = list()
i = 1
for (var in a){
best_features[i] <- which(colnames(db_train) == var)
i = i+1
}
View(best_features)
best_features[3]
best_features[3][0]
best_features[3]
best_features[1]
best_features[2]
save(best_features, file = "0063828_Vasile_challenge2_MCICNfeat.RData") # saving training features (models)
### LOADING DATA / DATABASE SELECTION ###
setwd("D:\\Uni\\SL\\SL_Project_2\\")
db_train <- as.data.frame(read.csv(".\\dataset\\ADCNtrain.csv"))
db_test <- as.data.frame(read.csv(".\\dataset\\ADCNtest.csv"))
db_train$Labels <- as.factor(db_train$Labels)
# correlation
train_cor = cor(db_train[-c(1,ncol(db_train))])
remove(train_cor) # decluttering
# data imbalance exploration
numPositive <-length(which(db_train$Labels==levels(db_train$Labels)[1])) # ex: levels(db_train$Labels)[1] = "AD" for ADCN
numNegative <-length(which(db_train$Labels==levels(db_train$Labels)[2])) # coded for dynamic interchange of datasets
imb_idx <- imbalanceRatio(db_train, classAttr = "Labels")
# solving data imbalance
# balanced.train.data <- SMOTE(Labels ~., smote_data, perc.over = 100, perc.under = 200)
# “RACOG”, “RWO”, “ADASYN”, “ANSMOTE”, “SMOTE”, “MWMOTE”, “BLSMOTE”, “DBSMOTE”, “SLMOTE”, “RSLSMOTE”
# newSamples <- oversample(db_train[2:ncol(db_train)] ,method = "SMOTE",classAttr = 'Labels', ratio = imb_idx*2.5) # ADCN
# newSamples <- oversample(db_train[2:ncol(db_train)] ,method = "SMOTE",classAttr = 'Labels', ratio = imb_idx*4) # ADMCI
newSamples <- db_train[2:ncol(db_train)] # MCICN, with an imbalance index of ~0.58 is better left like this (rename just for semi-automation purpouses)
# new imbalance ratio
newSamples_imb_dx <- imbalanceRatio(newSamples, classAttr = "Labels") # check
# Normalization
norm_params <- preProcess(newSamples[-c(1,ncol(db_train))]) # getting normalization parameters
newSamples[-c(1,ncol(db_train))] <- predict(norm_params, newSamples[-c(1,ncol(db_train))]) # applying them
db_test <- predict(norm_params, db_test) # applying them to test data
# Renaming
x_train <- newSamples
y_train <- as.factor(x_train$Labels)
# Feature Selection based on medical insight
a <- c(names(select(x_train,matches("HLA"))),
names(select(x_train,matches("SLC6"))),
names(select(x_train,matches("SRP"))),
names(select(x_train,matches("hippoca"))),
names(select(x_train,matches("frontal"))),
names(select(x_train,matches("tempo"))),
names(select(x_train,matches("parie"))),
names(select(x_train,matches("amyg"))),
names(select(x_train,matches("call"))))
x_train <- select(x_train, a)
############################## SVMS #########################################
x_train$Labels <- y_train # necesary only for SVM training format
set.seed(42) # because 42 it's the answer to everything
train.control <- trainControl(method = "cv", repeats = 5, number = 5,
classProbs =  TRUE)
svmRadial.fit <- train(Labels ~ .,
data = x_train,
method = "svmRadial",
# preProc = c("center", "scale"),
# tuneGrid = expand.grid(sigma = seq(from = 0.0016, to = 0.003, by = 0.0002),
#                        C = seq(from = 1.5, to = 3, by = 0.10)),
trControl = train.control)
print(svmRadial.fit)
y_pred_svmRadial <- predict(svmRadial.fit, x_train) # predicting on training data
roc_svmRadial <- roc(as.numeric(y_train), as.numeric(y_pred_svmRadial)) # builds a ROC curve and returns a “roc” object
plot(roc_svmRadial, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(roc_svmRadial$auc[[1]],2))) # plot AUC
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
mcc_svmRadial <- mcc(y_pred_svmRadial, y_train)
x_train$Labels <- y_train # necesary only for SVM training format
set.seed(42) # because 42 it's the answer to everything
train.control <- trainControl(method = "cv", repeats = 5, number = 5,
classProbs =  TRUE)
svmRadial.fit <- train(Labels ~ .,
data = x_train,
method = "svmRadial",
# preProc = c("center", "scale"),
tuneGrid = expand.grid(sigma = seq(from = 0.0016, to = 0.003, by = 0.0002),
C = seq(from = 1.5, to = 3, by = 0.10)),
trControl = train.control)
print(svmRadial.fit)
y_pred_svmRadial <- predict(svmRadial.fit, x_train) # predicting on training data
roc_svmRadial <- roc(as.numeric(y_train), as.numeric(y_pred_svmRadial)) # builds a ROC curve and returns a “roc” object
plot(roc_svmRadial, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(roc_svmRadial$auc[[1]],2))) # plot AUC
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
mcc_svmRadial <- mcc(y_pred_svmRadial, y_train)
train.control <- trainControl(method = "cv", repeats = 5, number = 5,
classProbs =  TRUE)
svmPoly.fit <- train(Labels ~ .,
data = x_train,
method = "svmPoly",
# preProc = c("center", "scale"),
# tuneGrid = expand.grid(degree = seq(from = 5, to = 7, by = 1),
#                        scale = seq(from = 0.1, to = 0.2, by = 0.05),
#                        C = seq(from = 0.25, to = 1, by = 0.25)),
trControl = train.control)
print(svmPoly.fit)
y_pred_svmPoly <- predict(svmPoly.fit, x_train) # predicting on training data
roc_svmPoly <- roc(as.numeric(y_train), as.numeric(y_pred_svmPoly)) # builds a ROC curve and returns a “roc” object
plot(roc_svmPoly, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(roc_svmPoly$auc[[1]],2))) # plot AUC
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
mcc_svmPoly <- mcc(y_pred_svmPoly, y_train)
final_pred <- predict(svmPoly.fit, db_test)
final_db <- as.data.frame(db_test[1])
final_db$Labels <- final_pred
save(final_db, file = "0063828_Vasile_challenge2_ADCNres.RData") # saving training features (models)
best_features = list()
i = 1
for (var in a){
best_features[i] <- which(colnames(db_train) == var)
i = i+1
}
save(best_features, file = "0063828_Vasile_challenge2_ADCNfeat.RData") # saving training features (models)
db_train <- as.data.frame(read.csv(".\\dataset\\ADMCItrain.csv"))
db_test <- as.data.frame(read.csv(".\\dataset\\ADMCItest.csv"))
db_train$Labels <- as.factor(db_train$Labels)
# correlation
train_cor = cor(db_train[-c(1,ncol(db_train))])
remove(train_cor) # decluttering
# data imbalance exploration
numPositive <-length(which(db_train$Labels==levels(db_train$Labels)[1])) # ex: levels(db_train$Labels)[1] = "AD" for ADCN
numNegative <-length(which(db_train$Labels==levels(db_train$Labels)[2])) # coded for dynamic interchange of datasets
imb_idx <- imbalanceRatio(db_train, classAttr = "Labels")
# solving data imbalance
# balanced.train.data <- SMOTE(Labels ~., smote_data, perc.over = 100, perc.under = 200)
# “RACOG”, “RWO”, “ADASYN”, “ANSMOTE”, “SMOTE”, “MWMOTE”, “BLSMOTE”, “DBSMOTE”, “SLMOTE”, “RSLSMOTE”
# newSamples <- oversample(db_train[2:ncol(db_train)] ,method = "SMOTE",classAttr = 'Labels', ratio = imb_idx*2.5) # ADCN
# newSamples <- oversample(db_train[2:ncol(db_train)] ,method = "SMOTE",classAttr = 'Labels', ratio = imb_idx*4) # ADMCI
newSamples <- db_train[2:ncol(db_train)] # MCICN, with an imbalance index of ~0.58 is better left like this (rename just for semi-automation purpouses)
# solving data imbalance
# balanced.train.data <- SMOTE(Labels ~., smote_data, perc.over = 100, perc.under = 200)
# “RACOG”, “RWO”, “ADASYN”, “ANSMOTE”, “SMOTE”, “MWMOTE”, “BLSMOTE”, “DBSMOTE”, “SLMOTE”, “RSLSMOTE”
newSamples <- oversample(db_train[2:ncol(db_train)] ,method = "SMOTE",classAttr = 'Labels', ratio = imb_idx*2.5) # ADCN
# new imbalance ratio
newSamples_imb_dx <- imbalanceRatio(newSamples, classAttr = "Labels") # check
# solving data imbalance
# balanced.train.data <- SMOTE(Labels ~., smote_data, perc.over = 100, perc.under = 200)
# “RACOG”, “RWO”, “ADASYN”, “ANSMOTE”, “SMOTE”, “MWMOTE”, “BLSMOTE”, “DBSMOTE”, “SLMOTE”, “RSLSMOTE”
# newSamples <- oversample(db_train[2:ncol(db_train)] ,method = "SMOTE",classAttr = 'Labels', ratio = imb_idx*2.5) # ADCN
newSamples <- oversample(db_train[2:ncol(db_train)] ,method = "SMOTE",classAttr = 'Labels', ratio = imb_idx*4) # ADMCI
### LOADING PACKAGES ###
library(tidyverse) # really dunno
library(eqs2lavaan) # for plotting covariance
library(GGally) # plotting correlation
library(FNN) # knn
library(readr) # string to number
library(Metrics)
library(caret) # normalization
library(Directional) # another knn (regression tuning)
library(dplyr) # for finding strings in column names
library(imager) # dealing with images
library(ggplot2) # plotting
library(cowplot) # for nicer ggplots
library(e1071) # SVM
library (ROCR)
library(MLmetrics)
library(AUC)
library(mltools)
library(rpart)
library(pROC)
library(imbalance)
library(performanceEstimation)
library(DMwR)
### LOADING DATA / DATABASE SELECTION ###
setwd("D:\\Uni\\SL\\SL_Project_2\\")
# db_train <- as.data.frame(read.csv(".\\dataset\\ADCNtrain.csv"))
# db_test <- as.data.frame(read.csv(".\\dataset\\ADCNtest.csv"))
db_train <- as.data.frame(read.csv(".\\dataset\\ADMCItrain.csv"))
db_test <- as.data.frame(read.csv(".\\dataset\\ADMCItest.csv"))
# db_train <- as.data.frame(read.csv(".\\dataset\\MCICNtrain.csv"))
# db_test <- as.data.frame(read.csv(".\\dataset\\MCICNtest.csv"))
db_train$Labels <- as.factor(db_train$Labels)
### EXPLORING DATA ###
# correlation
train_cor = cor(db_train[-c(1,ncol(db_train))])
heatmap(train_cor) # correlation matrix
remove(train_cor) # decluttering
# data imbalance exploration
numPositive <-length(which(db_train$Labels==levels(db_train$Labels)[1])) # ex: levels(db_train$Labels)[1] = "AD" for ADCN
numNegative <-length(which(db_train$Labels==levels(db_train$Labels)[2])) # coded for dynamic interchange of datasets
imb_idx <- imbalanceRatio(db_train, classAttr = "Labels")
### FEATURE ENGINEERING & SELECTION ###
# solving data imbalance
# balanced.train.data <- SMOTE(Labels ~., smote_data, perc.over = 100, perc.under = 200)
# “RACOG”, “RWO”, “ADASYN”, “ANSMOTE”, “SMOTE”, “MWMOTE”, “BLSMOTE”, “DBSMOTE”, “SLMOTE”, “RSLSMOTE”
# newSamples <- oversample(db_train[2:ncol(db_train)] ,method = "SMOTE",classAttr = 'Labels', ratio = imb_idx*2.5) # ADCN
newSamples <- oversample(db_train[2:ncol(db_train)] ,method = "SMOTE",classAttr = 'Labels', ratio = imb_idx*4) # ADMCI
# newSamples <- db_train[2:ncol(db_train)] # MCICN, with an imbalance index of ~0.58 is better left like this (rename just for semi-automation purpouses)
# new imbalance ratio
newSamples_imb_dx <- imbalanceRatio(newSamples, classAttr = "Labels") # check
# Normalization
norm_params <- preProcess(newSamples[-c(1,ncol(db_train))]) # getting normalization parameters
newSamples[-c(1,ncol(db_train))] <- predict(norm_params, newSamples[-c(1,ncol(db_train))]) # applying them
db_test <- predict(norm_params, db_test) # applying them to test data
# Renaming
x_train <- newSamples
y_train <- as.factor(x_train$Labels)
# Feature Selection based on medical insight
a <- c(names(select(x_train,matches("HLA"))),
names(select(x_train,matches("SLC6"))),
names(select(x_train,matches("SRP"))),
names(select(x_train,matches("hippoca"))),
names(select(x_train,matches("frontal"))),
names(select(x_train,matches("tempo"))),
names(select(x_train,matches("parie"))),
names(select(x_train,matches("amyg"))),
names(select(x_train,matches("call"))))
x_train <- select(x_train, a)
x_train$Labels <- y_train # necesary only for SVM training format
set.seed(42) # because 42 it's the answer to everything
train.control <- trainControl(method = "cv", repeats = 5, number = 5,
classProbs =  TRUE)
svmRadial.fit <- train(Labels ~ .,
data = x_train,
method = "svmRadial",
# preProc = c("center", "scale"),
tuneGrid = expand.grid(sigma = seq(from = 0.0016, to = 0.003, by = 0.0002),
C = seq(from = 1.5, to = 3, by = 0.10)),
trControl = train.control)
print(svmRadial.fit)
y_pred_svmRadial <- predict(svmRadial.fit, x_train) # predicting on training data
roc_svmRadial <- roc(as.numeric(y_train), as.numeric(y_pred_svmRadial)) # builds a ROC curve and returns a “roc” object
plot(roc_svmRadial, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(roc_svmRadial$auc[[1]],2))) # plot AUC
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
mcc_svmRadial <- mcc(y_pred_svmRadial, y_train)
final_pred <- predict(svmPoly.fit, db_test)
final_db <- as.data.frame(db_test[1])
final_db$Labels <- final_pred
save(final_db, file = "0063828_Vasile_challenge2_ADMCIres.RData") # saving training features (models)
best_features = list()
i = 1
for (var in a){
best_features[i] <- which(colnames(db_train) == var)
i = i+1
}
save(best_features, file = "0063828_Vasile_challenge2_ADMCIfeat.RData") # saving training features (models)
## SAVE ##
final_pred <- predict(svmRadial.fit, db_test)
final_db <- as.data.frame(db_test[1])
final_db$Labels <- final_pred
save(final_db, file = "0063828_Vasile_challenge2_ADMCIres.RData") # saving training features (models)
best_features = list()
i = 1
for (var in a){
best_features[i] <- which(colnames(db_train) == var)
i = i+1
}
save(best_features, file = "0063828_Vasile_challenge2_ADMCIfeat.RData") # saving training features (models)
## SAVE ##
### LOADING DATA / DATABASE SELECTION ###
setwd("D:\\Uni\\SL\\SL_Project_2\\")
db_train <- as.data.frame(read.csv(".\\dataset\\ADCNtrain.csv"))
db_test <- as.data.frame(read.csv(".\\dataset\\ADCNtest.csv"))
# db_train <- as.data.frame(read.csv(".\\dataset\\ADMCItrain.csv"))
# db_test <- as.data.frame(read.csv(".\\dataset\\ADMCItest.csv"))
# db_train <- as.data.frame(read.csv(".\\dataset\\MCICNtrain.csv"))
# db_test <- as.data.frame(read.csv(".\\dataset\\MCICNtest.csv"))
db_train$Labels <- as.factor(db_train$Labels)
### EXPLORING DATA ###
# correlation
train_cor = cor(db_train[-c(1,ncol(db_train))])
heatmap(train_cor) # correlation matrix
remove(train_cor) # decluttering
# data imbalance exploration
numPositive <-length(which(db_train$Labels==levels(db_train$Labels)[1])) # ex: levels(db_train$Labels)[1] = "AD" for ADCN
numNegative <-length(which(db_train$Labels==levels(db_train$Labels)[2])) # coded for dynamic interchange of datasets
imb_idx <- imbalanceRatio(db_train, classAttr = "Labels")
### FEATURE ENGINEERING & SELECTION ###
# solving data imbalance
# balanced.train.data <- SMOTE(Labels ~., smote_data, perc.over = 100, perc.under = 200)
# “RACOG”, “RWO”, “ADASYN”, “ANSMOTE”, “SMOTE”, “MWMOTE”, “BLSMOTE”, “DBSMOTE”, “SLMOTE”, “RSLSMOTE”
newSamples <- oversample(db_train[2:ncol(db_train)] ,method = "SMOTE",classAttr = 'Labels', ratio = imb_idx*2.5) # ADCN
# newSamples <- oversample(db_train[2:ncol(db_train)] ,method = "SMOTE",classAttr = 'Labels', ratio = imb_idx*4) # ADMCI
# newSamples <- db_train[2:ncol(db_train)] # MCICN, with an imbalance index of ~0.58 is better left like this (rename just for semi-automation purpouses)
# new imbalance ratio
newSamples_imb_dx <- imbalanceRatio(newSamples, classAttr = "Labels") # check
# Normalization
norm_params <- preProcess(newSamples[-c(1,ncol(db_train))]) # getting normalization parameters
newSamples[-c(1,ncol(db_train))] <- predict(norm_params, newSamples[-c(1,ncol(db_train))]) # applying them
db_test <- predict(norm_params, db_test) # applying them to test data
# Renaming
x_train <- newSamples
y_train <- as.factor(x_train$Labels)
# Feature Selection based on medical insight
a <- c(names(select(x_train,matches("HLA"))),
names(select(x_train,matches("SLC6"))),
names(select(x_train,matches("SRP"))),
names(select(x_train,matches("hippoca"))),
names(select(x_train,matches("frontal"))),
names(select(x_train,matches("tempo"))),
names(select(x_train,matches("parie"))),
names(select(x_train,matches("amyg"))),
names(select(x_train,matches("call"))))
x_train <- select(x_train, a)
x_train$Labels <- y_train # necesary only for SVM training format
set.seed(42) # because 42 it's the answer to everything
train.control <- trainControl(method = "cv", repeats = 5, number = 5,
classProbs =  TRUE)
svmRadial.fit <- train(Labels ~ .,
data = x_train,
method = "svmRadial",
# preProc = c("center", "scale"),
tuneGrid = expand.grid(sigma = seq(from = 0.0016, to = 0.003, by = 0.0002),
C = seq(from = 1.5, to = 3, by = 0.10)),
trControl = train.control)
print(svmRadial.fit)
y_pred_svmRadial <- predict(svmRadial.fit, x_train) # predicting on training data
roc_svmRadial <- roc(as.numeric(y_train), as.numeric(y_pred_svmRadial)) # builds a ROC curve and returns a “roc” object
plot(roc_svmRadial, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(roc_svmRadial$auc[[1]],2))) # plot AUC
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
mcc_svmRadial <- mcc(y_pred_svmRadial, y_train)
## SAVE ##
final_pred <- predict(svmRadial.fit, db_test)
final_db <- as.data.frame(db_test[1])
final_db$Labels <- final_pred
save(final_db, file = "0063828_Vasile_challenge2_ADCNres.RData") # saving training features (models)
best_features = list()
i = 1
for (var in a){
best_features[i] <- which(colnames(db_train) == var)
i = i+1
}
save(best_features, file = "0063828_Vasile_challenge2_ADCNfeat.RData") # saving training features (models)
## SAVE ##
load("0063828_Vasile_challenge2_ADCNres.RData") # saving training features (models)
load("0063828_Vasile_challenge2_ADCNfeat.RData") # saving training features (models)
best_features
unlist(brest_features)
unlist(best_features)
a <- unlist(best_features)
save(unlist(best_features), file = "0063828_Vasile_challenge2_ADCNfeat.RData") # saving training features (models)
save(unlist(best_features), file = "0063828_Vasile_challenge2_MCICNfeat.RData") # saving training features (models)
save(unlist(best_features), file = "0063828_Vasile_challenge2_ADMCIfeat.RData") # saving training features (models)
### LOADING DATA / DATABASE SELECTION ###
setwd("D:\\Uni\\SL\\SL_Project_2\\")
### TESTING SAVE ###
save(unlist(best_features), file = "0063828_Vasile_challenge2_ADCNfeat.RData") # saving training features (models)
### TESTING SAVE ###
a <- unlist(best_features)
save(a, file = "0063828_Vasile_challenge2_ADCNfeat.RData") # saving training features (models)
save(a, file = "0063828_Vasile_challenge2_MCICNfeat.RData") # saving training features (models)
save(a, file = "0063828_Vasile_challenge2_ADMCIfeat.RData") # saving training features (models)
load("0063828_Vasile_challenge2_ADCNres.RData") # saving training features (models)
load("0063828_Vasile_challenge2_ADCNfeat.RData") # saving training features (models)
load("0063828_Vasile_challenge2_ADCNres.RData") # saving training features (models)
load("0063828_Vasile_challenge2_ADCNfeat.RData") # saving training features (models)
### TESTING SAVE ###
best_features <- a
save(best_features, file = "0063828_Vasile_challenge2_ADCNfeat.RData") # saving training features (models)
save(best_features, file = "0063828_Vasile_challenge2_MCICNfeat.RData") # saving training features (models)
save(best_features, file = "0063828_Vasile_challenge2_ADMCIfeat.RData") # saving training features (models)
load("0063828_Vasile_challenge2_ADCNres.RData") # saving training features (models)
load("0063828_Vasile_challenge2_ADCNfeat.RData") # saving training features (models)
load("0063828_Vasile_challenge2_ADCNres.RData") # saving training features (models)
load("0063828_Vasile_challenge2_ADMCIfeat.RData") # saving training features (models)
